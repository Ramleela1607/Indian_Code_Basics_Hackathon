{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ab6c33a-86ef-4b22-a51f-2e31048ca91d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### GOLD LAYER LOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dcdf9f6-c99e-4f0b-9771-1148254ab569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Purpose:**  \n",
    "This notebook performs the **Gold layer aggregation** for farm advisory, combining multiple Silver-layer datasets (soil, crop, market, pest, rainfall) into a single enriched dataset for downstream analytics and AI insights.\n",
    "\n",
    "**Workflow:**  \n",
    "1. Load Silver tables from the Delta Lake (soil, crop, market, pest, rainfall).  \n",
    "2. Rename columns and cast numeric fields for consistency.  \n",
    "3. Join datasets on **date** and **city** to create a unified Gold table.  \n",
    "4. Compute derived business metrics:\n",
    "   - `yieldPredictionScore`  \n",
    "   - `profitabilityIndex`  \n",
    "   - `pestRiskCategory`  \n",
    "   - `soilMoistureCategory`  \n",
    "   - `sustainabilityScore`  \n",
    "   - `description` (text summary for each crop-city-date)\n",
    "5. Save the resulting Gold table to Delta format for analytics and AI workflows.  \n",
    "6. Write audit logs for each task (success/failure) to an audit Delta table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2407a0ac-a4a2-47d5-aad7-0ead4e617c17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Dashboard & Visualization:**  \n",
    "- Visualize **yield trends** by city and crop.  \n",
    "- View **profitability ranking** of top crops.  \n",
    "- Heatmaps for **monthly crop price trends**.  \n",
    "- Supports interactive plots using **Matplotlib** and **Seaborn** in the same notebook.\n",
    "\n",
    "**Notes:**  \n",
    "- Update the variables `catalog_name`, `schema_name_silver`, `schema_name_gold`, `audit_schema_name`, and `workflow_job_id` to match your Databricks environment.  \n",
    "- Ensure the cluster has sufficient memory for joining multiple Silver tables and computing derived metrics.  \n",
    "- This notebook is designed to feed downstream AI and vector-based query systems for farm advisory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40beefe-192b-441d-ac4d-9659990f640c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, when, lit, concat_ws, current_timestamp\n",
    ")\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, current_timestamp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d807c0c-b7c3-4528-94a7-f8aec50a9ee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS databricks_free_edition.databricks_gold;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "518ee92b-b85e-41aa-b831-7ae09d5f4e07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"databricks_free_edition\"\n",
    "schema_name = \"databricks_gold\"\n",
    "schema_name_silver = \"databricks_silver\"\n",
    "audit_schema_name = \"audit_logs\"\n",
    "schema_name_gold = \"databricks_gold\"\n",
    "workflow_job_id = dbutils.widgets.get(\"workflow_job_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1ca816f-3a40-4166-a280-e42bf3745e97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "db_silver = f\"{catalog_name}.{schema_name_silver}\"\n",
    "db_gold = f\"{catalog_name}.{schema_name_gold}\"\n",
    "db_audit = f\"{catalog_name}.{audit_schema_name}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Audit Log Function\n",
    "# -----------------------------\n",
    "\n",
    "def write_audit(workflow_job_id,task, status, start_ts, end_ts, message=\"\"):\n",
    "    \"\"\"Write task audit record.\"\"\"\n",
    "    rows = [(workflow_job_id,task, status, start_ts, end_ts, message)]\n",
    "    schema = \"workflow_job_id STRING, task STRING, status STRING, start_time TIMESTAMP, end_time TIMESTAMP, message STRING\"\n",
    "    spark.createDataFrame(rows, schema=schema) \\\n",
    "        .write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(f\"{db_audit}.error_reporting_audit\")\n",
    "\n",
    "# -----------------------------\n",
    "# GOLD AGGREGATION\n",
    "# -----------------------------\n",
    "task_name_gold = \"gold_layer_farm_aggregation\"\n",
    "start_ts_gold = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "\n",
    "try:\n",
    "    print(\"\uD83D\uDE9C Starting Gold layer aggregation...\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Helper: rename and cast numeric columns\n",
    "    # -----------------------------\n",
    "    def rename_and_cast(df, prefix):\n",
    "        for c in df.columns:\n",
    "            df = df.withColumnRenamed(c, f\"{prefix}_{c}\")\n",
    "        num_cols = [\n",
    "            \"soilMoisture\", \"temperature\", \"humidity\", \"precipitationIntensity\",\n",
    "            \"cropHealthScore\", \"ndviIndex\", \"leafMoisture\", \"cropPricePerQuintal\", \"pestRisk\", \"rainfall\"\n",
    "        ]\n",
    "        for c in num_cols:\n",
    "            if f\"{prefix}_{c}\" in df.columns:\n",
    "                df = df.withColumn(f\"{prefix}_{c}\", col(f\"{prefix}_{c}\").cast(DoubleType()))\n",
    "        return df\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load Silver Tables\n",
    "    # -----------------------------\n",
    "    soil = rename_and_cast(spark.table(f\"{db_silver}.silver_soil\"), \"soil\")\n",
    "    crop = rename_and_cast(spark.table(f\"{db_silver}.silver_crop\"), \"crop\")\n",
    "    market = rename_and_cast(spark.table(f\"{db_silver}.silver_market\"), \"market\")\n",
    "    pest = rename_and_cast(spark.table(f\"{db_silver}.silver_pest\"), \"pest\")\n",
    "    rainfall = rename_and_cast(spark.table(f\"{db_silver}.silver_rainfall\"), \"rainfall\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Join Datasets on date + city\n",
    "    # -----------------------------\n",
    "    gold = (\n",
    "        soil.join(crop, (soil[\"soil_date\"] == crop[\"crop_date\"]) & (soil[\"soil_city\"] == crop[\"crop_city\"]), \"inner\")\n",
    "            .join(market, (soil[\"soil_date\"] == market[\"market_date\"]) & (soil[\"soil_city\"] == market[\"market_city\"]), \"inner\")\n",
    "            .join(pest, (soil[\"soil_date\"] == pest[\"pest_date\"]) & (soil[\"soil_city\"] == pest[\"pest_city\"]), \"inner\")\n",
    "            .join(rainfall, (soil[\"soil_date\"] == rainfall[\"rainfall_date\"]) & (soil[\"soil_city\"] == rainfall[\"rainfall_city\"]), \"inner\")\n",
    "            .drop(\"crop_date\",\"market_date\",\"pest_date\",\"rainfall_date\",\n",
    "                  \"crop_city\",\"market_city\",\"pest_city\",\"rainfall_city\")\n",
    "            .withColumnRenamed(\"soil_date\",\"date\")\n",
    "            .withColumnRenamed(\"soil_city\",\"city\")\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Business Metrics / Derived Columns\n",
    "    # -----------------------------\n",
    "    gold = (\n",
    "        gold\n",
    "        .withColumn(\"yieldPredictionScore\", col(\"soil_soilMoisture\") * col(\"crop_cropHealthScore\") / 100)\n",
    "        .withColumn(\"profitabilityIndex\", col(\"yieldPredictionScore\") * col(\"crop_cropPricePerQuintal\") / 100)\n",
    "        .withColumn(\"pestRiskCategory\",\n",
    "                    when(col(\"pest_pestRisk\") > 70, \"High\")\n",
    "                    .when(col(\"pest_pestRisk\") > 40, \"Medium\")\n",
    "                    .otherwise(\"Low\"))\n",
    "        .withColumn(\"soilMoistureCategory\",\n",
    "                    when(col(\"soil_soilMoisture\") < 30, \"Dry\")\n",
    "                    .when(col(\"soil_soilMoisture\") < 60, \"Normal\")\n",
    "                    .otherwise(\"Wet\"))\n",
    "        .withColumn(\"sustainabilityScore\",\n",
    "                    (col(\"yieldPredictionScore\") - col(\"pest_pestRisk\")) / 10)\n",
    "        .withColumn(\"description\",\n",
    "                    concat_ws(\" \",\n",
    "                        lit(\"Crop:\"), col(\"market_cropName\"),\n",
    "                        lit(\"in\"), col(\"city\"),\n",
    "                        lit(\"has soil moisture\"), col(\"soil_soilMoisture\"),\n",
    "                        lit(\"pest risk\"), col(\"pestRiskCategory\"),\n",
    "                        lit(\"yield score\"), col(\"yieldPredictionScore\"),\n",
    "                        lit(\"profitability\"), col(\"profitabilityIndex\"),\n",
    "                        lit(\"rainfall(mm)\"), col(\"rainfall_rainfallMm\")\n",
    "                    ))\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save Gold Table\n",
    "    # -----------------------------\n",
    "    gold_table = f\"{db_gold}.gold_farm_advisor\"\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {gold_table}\")\n",
    "    gold.write.format(\"delta\").mode(\"overwrite\").saveAsTable(gold_table)\n",
    "\n",
    "    end_ts_gold = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "    write_audit(workflow_job_id, task_name_gold, \"SUCCESS\", start_ts_gold, end_ts_gold, \"Gold table created\")\n",
    "    print(f\"✅ Gold table created successfully: {gold_table}\")\n",
    "\n",
    "except Exception as e:\n",
    "    end_ts_gold = spark.sql(\"SELECT current_timestamp()\").collect()[0][0]\n",
    "    tb = traceback.format_exc()\n",
    "    write_audit(workflow_job_id, task_name_gold, \"FAILED\", start_ts_gold, end_ts_gold, str(tb)[:4000])\n",
    "    print(\"❌ Gold aggregation failed. See audit table for details.\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "508fe7f5-cfbe-4f94-8654-64f82a3b610f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Yield trend by City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d12b54de-744b-47d3-a9bf-37b5aeca69f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(gold_table).toPandas()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(x=\"date\", y=\"yieldPredictionScore\", hue=\"city\", data=df)\n",
    "plt.title(\"Yield Prediction Trend by City\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Yield Score\")\n",
    "plt.xticks(rotation=45)\n",
    "display(plt.gcf())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "908135d8-8d1b-45d1-a5e5-e136183285f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Top 10 profitable crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ba8edab-02a2-492a-84c8-797fef3a56b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_profit = (\n",
    "    df.groupby(\"market_cropName\")[\"profitabilityIndex\"]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .sort_values(\"profitabilityIndex\", ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=\"profitabilityIndex\", y=\"market_cropName\", data=top_profit)\n",
    "plt.title(\"Top 10 Most Profitable Crops\")\n",
    "plt.xlabel(\"Profitability Index\")\n",
    "plt.ylabel(\"Crop\")\n",
    "display(plt.gcf())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d12cfae-4a3b-4f1c-aa63-47ab634d9fea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  --- PRICE TREND HEATMAP ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "304b7b2a-eec7-4fde-bcfd-0f5cd032e98f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ensure date is datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Extract month name\n",
    "df[\"month\"] = df[\"date\"].dt.strftime(\"%b\")\n",
    "\n",
    "# Pivot table: Rows = Crop, Columns = Month, Values = Avg Price\n",
    "heatmap_df = (\n",
    "    df.groupby([\"market_cropName\", \"month\"])[\"crop_cropPricePerQuintal\"]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .pivot(index=\"market_cropName\", columns=\"month\", values=\"crop_cropPricePerQuintal\")\n",
    ")\n",
    "\n",
    "# Sort months properly (instead of alphabetical)\n",
    "month_order = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "heatmap_df = heatmap_df.reindex(columns=[m for m in month_order if m in heatmap_df.columns])\n",
    "\n",
    "# Plot Heatmap\n",
    "plt.figure(figsize=(14,10))\n",
    "sns.heatmap(heatmap_df, annot=True, fmt=\".1f\", linewidths=.5)\n",
    "plt.title(\"\uD83D\uDCC8 Average Crop Price Trend Heatmap (₹ per Quintal)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Crop\")\n",
    "\n",
    "display(plt.gcf())  \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7187789842795814,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold_transformation_layer_load",
   "widgets": {
    "user_query": {
     "currentValue": "what are all the city crops data is available with you",
     "nuid": "b6b8f8b2-8b37-47c8-9aee-18151e69edf5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "what are all the city crops data is available",
      "label": "Farm Chat Query",
      "name": "user_query",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "what are all the city crops data is available",
      "label": "Farm Chat Query",
      "name": "user_query",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}